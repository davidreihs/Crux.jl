"""
Off-policy generative adversarial imitation learning (GAIL) solver.

```julia
OffPolicyGAIL(;
    ,
    S, 
    _demo, 
    _ndas::Array{ExperienceBuffer} = ExperienceBuffer[], 
    normalize_demo::Bool=true, 
    D::ContinuousNetwork, 
    solver=SAC, 
    d_opt::NamedTuple=(epochs=5,), 
    log::NamedTuple=(;), 
    kwargs...)
```
"""
function OffPolicyGAIL(;
        ,
        S, 
        _demo, 
        _ndas::Array{ExperienceBuffer} = ExperienceBuffer[], 
        normalize_demo::Bool=true, 
        add_noise::Bool=false,
        D::ContinuousNetwork, 
        solver=SAC, 
        d_opt::NamedTuple=(epochs=5,), 
        log::NamedTuple=(;), 
        kwargs...)
                        
    # Define the training parameters for the desciminator
    d_opt = TrainingParams(;name="discriminator_", loss=()->nothing, d_opt...)
    
    # Setup NDA parameters
    N_nda = length(_ndas)
    位_nda = Float32(-1 / N_nda)
    N_datasets = 2 + N_nda
    
    println("位nda: $(位_nda), N_datasets:$(N_datasets), N_nda:$(N_nda)")

    # Normalize and/or change device of expert and NDA data
    dev = device()
    A = action_space()
    normalize_demo && (_demo = normalize!(deepcopy(_demo), S, A))
    _demo = _demo |> dev
    for i in 1:N_nda
        _ndas[i] = normalize_demo && normalize!(deepcopy(_ndas[i]), S, A)
        _ndas[i] = _ndas[i] |> dev
    end

    # Build the solver
     = solver(;=, 
                S=S,
                log=(dir="log/offpolicygail", period=500, log...),
                kwargs...)
            
    # Setup the training of the discriminator
    B = d_opt.batch_size
    
    # These are minibatch buffers
    _batch = buffer_like(.buffer, capacity=B, device=dev)
    _demo_batch = deepcopy(_batch)
    _demo__batch = deepcopy(_batch)
    _ndas_batch = [deepcopy(_batch) for _nda in _ndas]
    _ndas__batch = [deepcopy(_batch) for _nda in _ndas]
    
    function GAIL_callback(; info=Dict(), kwargs...)
        for i=1:d_opt.epochs
            
            # Sample minibatchs
            rand!(_demo_batch, _demo)
            # rand!(_demo__batch, _demo)
            # _demo__batch.data[:a] = action(, _demo__batch[:s])
            rand!(_batch, .buffer)
            for i in 1:N_nda
                rand!(_ndas_batch[i], _ndas[i])
                # rand!(_ndas__batch[i], _ndas[i])
                # _ndas__batch[i].data[:a] = action(, _ndas__batch[i][:s])
            end
            # Concatenate minibatches into on buffer
            _full = hcat(_demo_batch, _batch, _ndas_batch...)
            
            # concat inputs
            x = cat(flatten(_full[:s]), _full[:a], dims=1)
            
            # Add some noise (Optional)
            if add_noise
                x .+= Float32.(rand(Normal(0, 0.1f0), size(x))) |> dev
            else
                x = x |> dev
            end
            # Create labels
            y_demo = Flux.onehotbatch(ones(Int, B), 1:N_datasets)
            # y_demo_ = Flux.onehotbatch(2*ones(Int, B), 1:N_datasets)
            y_ = Flux.onehotbatch(2*ones(Int, B), 1:N_datasets)
            y_ndas = [Flux.onehotbatch((i+2)*ones(Int, B), 1:N_datasets) for i=1:N_nda]
            # y_ndas_ = [Flux.onehotbatch(2*ones(Int, B), 1:N_datasets) for i=1:N_nda]
            
            y = cat(y_demo, y_, y_ndas..., dims=2) |> dev
            
            println("size y:$(size(y)), size D(x):$(size(D(x)))")
            # println(gradient_penalty(D, x_demo, x_))
            # + 10f0 * gradient_penalty(D, x_demo, x_)
            train!(D, (;kwargs...) -> Flux.Losses.logitcrossentropy(D(x), y), d_opt, info=info)
        end
        
        # ## replace the bufffer
        # rand!(_demo_batch, _demo)
        # # rand!(_demo__batch, _demo)
        # # _demo__batch.data[:a] = action(, _demo__batch[:s])
        # rand!(_batch, .buffer)
        # for i in 1:N_nda
        #     rand!(_ndas_batch[i], _ndas[i])
        #     # rand!(_ndas__batch[i], _ndas[i])
        #     # _ndas__batch[i].data[:a] = action(, _ndas__batch[i][:s])
        # end
        # 
        # _full = hcat(_demo_batch, _batch, _ndas_batch...)
        # 
        # for k in keys()
        #     .data[k] = _full.data[k]
        # end
        # .elements = _full.elements
        # .next_ind = _full.next_ind
        
        ## Compute the rewards
        D_out = Flux.softmax(value(D, flatten([:s]), [:a]))
        w = [1f0, 0f0, 位_nda*ones(Float32, N_nda)...] |> dev
        
        [:r] .= sum((Base.log.(D_out .+ 1f-5) .- Base.log.(1f0 .- D_out .+ 1f-5)) .* w, dims=1)
    end
    
    .post_batch_callback = GAIL_callback
    
end

